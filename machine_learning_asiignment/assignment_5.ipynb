{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the key tasks that machine learning entails? What does data pre-processing imply?\n",
    "<br>\n",
    "Ans - >the key tasks that machine learning entails\n",
    "<br>\n",
    "1 .define the problem statement\n",
    "<br>\n",
    "2 . data collection from the various resources \n",
    "<br>\n",
    "3 . data preprocessing\n",
    "<br>\n",
    "4 .selection of the algorithm\n",
    "<br>\n",
    "5 . Training the model \n",
    "<br>\n",
    "6 . Evaluation of the model with different parameters\n",
    "<br>\n",
    "7 .hyperparameter tuning of the model\n",
    "<br>\n",
    "8 . Inferencing the model\n",
    "<br>\n",
    "In data preprocessing stage we are cleaning the data , bringing the data at same scale due to hudge variance in the dataset(Normalization and standarization) , selecting the only important features in the dataset and this stage will make the data is ready to used in machine learning model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Describe quantitative and qualitative data in depth. Make a distinction between the two.\n",
    "<br>\n",
    "Ans quantitative data is one of data whoose represent in the numerical in the nature and it have some kind of order and mathematical meaning.it is two types\n",
    "<br>\n",
    "i - Discreate quantitative data -> this data have only whole number. it can not be fractional data and generally visualized by the bar plot.Example : number of bank accounts,faimly memeber and number of college students.\n",
    "<br>\n",
    "ii - >continuous data -> this data can have whole number and as well fractional value in the  nature. it is generally visulized by using histogram.Example height of people, age of people.\n",
    "<br>\n",
    "qualitative is the characteristic data which has string and discreate data but it can not defiend by mathematically.It have two type\n",
    "<br>\n",
    "Nominal qualitative data:\n",
    "This type of data is mostly used to label data points based on other characteristics. Nominal data cannot be ordered in any way. For example: Classification of flowers into sub species based on characteristics like sepal length etc.\n",
    "<br>\n",
    "\n",
    "Ordinal qualitative data :\n",
    "This type of data is one that can be ordered. For example: Grades.\n",
    "\n",
    "Quantitative data is different from qualitative data as it does not have any numerical nature and do not have mathematical meaning. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a basic data collection that includes some sample records. Have at least one attribute from each of the machine learning data types.\n",
    "<br>\n",
    "ans - >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>grade</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nitin</td>\n",
       "      <td>23</td>\n",
       "      <td>A</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aryan</td>\n",
       "      <td>23</td>\n",
       "      <td>S</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surya</td>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aarya</td>\n",
       "      <td>23</td>\n",
       "      <td>B</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age grade  height\n",
       "0  Nitin   23     A     5.6\n",
       "1  Aryan   23     S     5.5\n",
       "2  surya   31     A     6.0\n",
       "3  Aarya   23     B     5.6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={\n",
    "    'Name':['Nitin','Aryan','surya','Aarya'],\n",
    "    'Age':[23,23,31,23],\n",
    "    'grade':['A','S','A','B'],\n",
    "    'height':[5.6,5.5,6,5.6]\n",
    "}\n",
    "import pandas as pd \n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What are the various causes of machine learning data issues? What are the ramifications?\n",
    "<br>\n",
    "Ans - >Machine learning data issues can arise from\n",
    "<br>\n",
    "Removing outliers from data having non-gaussian distribution.\n",
    "<br>\n",
    "Imputing data using numerical averages in case of non gaussian distribution.\n",
    "<br>\n",
    "Low number of data points\n",
    "<br>\n",
    "Data coming from a sample not representative of the population.\n",
    "<br>\n",
    "Improper data entry\n",
    "<br>\n",
    "Highly Collinear independent features\n",
    "<br>\n",
    "Ramifications can be overfitting, underfitting and low performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Demonstrate various approaches to categorical data exploration with appropriate examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.1\n",
      "  Downloading matplotlib-3.5.3-cp37-cp37m-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 27.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\nitin\\onedrive\\desktop\\computer vision project\\cnn classifier\\cnn-classifier-project\\env\\lib\\site-packages (from seaborn) (1.21.6)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\nitin\\onedrive\\desktop\\computer vision project\\cnn classifier\\cnn-classifier-project\\env\\lib\\site-packages (from seaborn) (4.3.0)\n",
      "Collecting pandas>=0.25\n",
      "  Using cached pandas-1.3.5-cp37-cp37m-win_amd64.whl (10.0 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nitin\\onedrive\\desktop\\computer vision project\\cnn classifier\\cnn-classifier-project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\nitin\\onedrive\\desktop\\computer vision project\\cnn classifier\\cnn-classifier-project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp37-cp37m-win_amd64.whl (54 kB)\n",
      "     --------------------------------------- 54.9/54.9 kB 60.8 kB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.4.0-cp37-cp37m-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 33.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nitin\\onedrive\\desktop\\computer vision project\\cnn classifier\\cnn-classifier-project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\nitin\\onedrive\\desktop\\computer vision project\\cnn classifier\\cnn-classifier-project\\env\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nitin\\onedrive\\desktop\\computer vision project\\cnn classifier\\cnn-classifier-project\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, pandas, matplotlib, seaborn\n",
      "Successfully installed cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.5.3 pandas-1.3.5 pillow-9.4.0 seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.load_dataset('tips')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How would the learning activity be affected if certain variables have missing values? Having said that, what can be done about it?Â¶\n",
    "Ans - >\n",
    "<br>\n",
    "Several sklearn algorithms assume that all features are numerical and have mathematical meaning to them. If they come across missing values, the algorithm breaks and the program breaks. Generally, missing data builds up poor performance of the machine learning model. Certain algorithms like Random Forest however can handle missing data, at the expense of performance.\n",
    "\n",
    "Missing values can be imputed if the data has gaussian distribution. If not, median can be used for imputation. Certain values can also be filled using pandas interpolate() that calculates what missing value should be, based on the previous values but this can only work for features like ID code. Another way is to use machine learning models to learn from the data and then fill the missing value with most probable value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Describe the various methods for dealing with missing data values in depth.\n",
    "<br>\n",
    "Ans - >\n",
    "Imputation\n",
    "If the data distribution is normal, then numerical averages can be used to fill missing data as most of the data would lie around the mean. If data is not normally distributed, median can be used for imputation of values as median is not affected by presence of outliers. pd.df.fillna() is used for imputations\n",
    "\n",
    "Removal of datapoint\n",
    "If there is a lot of data and the missing values are very low in numbers, then it may be better to simply remove that specific data point row. This will have little effect over performance of the machine learning model to be built. pd.df.drop() is used for this.\n",
    "\n",
    "Interpolate()\n",
    "Interpolate() of pandas library is used in cases where numerical data is following some trend. This trend calculated and values are filled based on it. This function will not work on any other scenarios.\n",
    "\n",
    "Build a machine learning model for filling data\n",
    "Machine learning models can learn from the data and then fill the missing value with most probable value. KNN models can be built for this purpose.\n",
    "\n",
    "Dropping column\n",
    "Removing an entire column which is filled with missing data might be our best bet for building a good machine learning model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What are the various data pre-processing techniques? Explain dimensionality reduction and function selection in a few words.\n",
    "<br>\n",
    "Ans - > Data Pre-Processing techniques:\n",
    "<br>\n",
    "1 .Data Cleaning\n",
    "<br>\n",
    "2 .Data Transformation\n",
    "<br>\n",
    "3 .Data Reduction\n",
    "<br>\n",
    "Dimensionality Reduction and feature selection are both methods of reducing the number of features a machine learning model would be trained on, so that effective space time complexity of algorithms can be minimized. Dimensionality Reduction is a method which relies on converting the features into a lower dimension while feature selection relies on including only those features that will contribute most to the performance of a machine learning model. Examples of Dimensionality Reduction are PCA and t-SNE. Examples of feature selection are forward feature selection and backward feature selection."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.i. What is the IQR? What criteria are used to assess it?Â¶\n",
    "<br>\n",
    "Ans - > IQR or Inter-Quartile Range is a measure of dispersion. It is formulated as (third quartile-1st quartile). It is dependent on only 50% of the data.\n",
    "\n",
    "First quartile and third quartile are required to assess Inter Quartile Range."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Describe the various components of a box plot in detail? When will the lower whisker surpass the upper whisker in length? How can box plots be used to identify outliers?\n",
    "<br>\n",
    "Ans - >A boxplot gives us the 5 point summary which includes first quartile(median of the first 50% of the data), third quartile(median for second 50% of the data), median or 2nd quartile(exact mid point of the entire data), maximum value and minimum value. It also has two whiskers which provide us with a visual position of minimum and maximum value, below and above which lies the threshold beyond which any data point will be shown as an outlier. Outliers are declared by using formula Q1-(1.5 * IQR) and Q3+(1.5 * IQR)\n",
    "\n",
    "Lower whisker surpasses the upper whisker if the data is right skewed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Make brief notes on any two of the following:\n",
    "i. Data collected at regular intervals\n",
    "Data collection can be in many different forms. One of the probabilistic sampling techniques used in Statistics is Stratified sampling in which data is collected at regular intervals but with a random start. It is used for its simplicity.\n",
    "\n",
    "iii. Use a cross-tab\n",
    "Cross tabs or cross tabulation are only used to find relations between two categorical variables where one categorical variable value would be giving row data and the other variable would give column data. Several tests like the chi square test can help find relations based on the cross tab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Make a comparison between:\n",
    "ii. Histogram and box plot\n",
    "Histograms are data visualizations used for continous quantitative data. Box Plots are data visualizations used for describing any quantitative data.\n",
    "\n",
    "Histograms are used for checking the distribution type. Box Plots are used for describing data in 5 point summary and detecting outliers in data.\n",
    "\n",
    "Granularity can be changed using bins in Histograms. Box Plots do no feature any control over granularity.\n",
    "\n",
    "iii. The average and median\n",
    "Average is a measure of numerical centrality of a distribution. Median is a measure of positional centrality of a distribution\n",
    "\n",
    "Average can also be referred to as the value that is closest to most number of values in a data. Median can also be referred to as the value which is exactly in the middle of a distribution.\n",
    "\n",
    "Averages are affected by presence of outliers. Medians are not affected by outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b38c3bc0eaef3f1554d3f3739b1c32441dbdadbbe4a274ea1a25508c79a0bde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
